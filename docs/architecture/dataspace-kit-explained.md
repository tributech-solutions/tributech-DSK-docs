---
title: DataSpace Kit Explained
summary: Description of architecture an system overview.
authors:
    - Patrick Lamplmair
---

This section provides an overview of the Tributech DataSpace Kit and its features.

The DataSpace Kit is designed to create ecosystems for trusted data sharing between businesses - this data could be sensor, process or even business data. Through the integrated Trust Layer, data sources can be upgraded with data verification capabilities that guarantees the traceability and auditability of consumed and delivered data.

Based on the containerized and modular architecture, the technology can be integrated into any kind of platform, cloud or on-premise system to support the technology stack of all participating stakeholders.

## The building blocks for a DataSpace Ecosystem

The Tributech DataSpace Kit consists of three building blocks that allows you to create your own DataSpace Ecosystem or to join an existing one. These building blocks are the DataSpace Hub, DataSpace Node and DataSpace Agent.

Every ecosystem consists of one single DataSpace Hub, a DataSpace Node for each participating stakeholder integrated in his infrastructure (cloud, hybrid or on-premise) and DataSpace Agents integrated into  each data source/device that requires the data verification and tracing capabilities.

![DataSpace Kit - Building Blocks](img/dsk-infographic.png)
*Fig.1: DataSpace Kit Building Blocks & Schema*

The distributed components of the DataSpace Kit are connected via channels to exchange the different kinds of data within an ecosystem. APIs provide an interface for the data integration within the infrastructure of each connected stakeholder.

## DataSpace Hub

The DataSpace Hub provides the metadata storage and the public key infrastucture that is required for setting up an ecosystem of DataSpace Nodes, he is responsible for:

- storing the metadata of published datasets
- adding new DataSpace Nodes to the ecosystem
- issuing of certificates
- managing public keys
- managing identities

>###Important Note:
>
>A DataSpace Hub is not on the route of the traffic for the data exchange and even a man-in-the-middle-attack would fail because the Hub has no private-key material of DataSpace Nodes or Agents.

## DataSpace Node

A DataSpace Node is acting as a gateway/broker that is required to participate in a DataSpace Ecosystem. It contains all services needed for the data exchange and data verification capabilities with other nodes inside a DataSpace Ecosystem. Each DataSpace Node is controlled by a person or organization.

With a DataSpace Node you can:

**Connect data** sources via API and combine selected data to datasets. The integrated web application provides an interface to generate the required metadata that defines a dataset. For each stream (not limited to a data format or type) a unique ID is generated which is used as a reference for the data source integration via the APIs of the Dataspace Node. With the unique IDs from data streams of a dataset, everyone inside your ecosystem can request and consume data that is referenced with this IDs.

**Share data** streams with your customers, suppliers and partners. The DataSpace Node allows every user to create individual and automated synchronization processes to exchange data, without the need to care about networking, data processing, authentication and encryption between the connected systems. The integrated web application covers the data sharing process for datasets via publish, request and grant workflows.

**Verify data** by checking the origin and integrity before you start using it. The included trust layer stores cryptographic proofs and signatures, which are submitted by the DataSpace Agents to ensure the cross-system auditability of data's authenticity and integrity for the whole ecosystem.

## DataSpace Agent

The DataSpace Agent is designed for an integration into the data source for providing cross-system data security for any type of device/source like e.g. sensors, IoT-devices, IoT-gateways, SCADA-systems, PPS-systems, ERP-systems and more. A scalable process for generating cryptographic proofs and a secure connection to the trust layer guarantees the raw data’s authenticity and integrity for an entire ecosystem of DataSpace Nodes.

![Trust Layer Schema](img/dataspace-agent-schema.png)
*Fig.2: DataSpace Agent Schema*

The DataSpace Agent enriches a data source in terms of security and reliability. In addition to the existing data telemetry, hashes and signatures are created for each data point/packet/portion and these proofs are transmitted via a dedicated authenticated and encrypted communication channel to the trust layer.

## Trust Layer

Referring to figure 3, each DataSpace Ecosystem includes a trust layer to store cryptographic proofs that are generated by the DataSpace Agents. This enables the data verification features for all stakeholders inside an ecosystem. Each DataSpace Node includes an instance of this trust layer.

![Trust Layer Schema](img/trust-layer-schema.png)
*Fig.3: DataSpace Kit Trust Layer Schema*

The trust layer of the DataSpace Kit provides an end-to-end solution for verifying data streams - starting from the generation of cryptographic proofs at the data source via DataSpace Agents - to the verification of the authenticity and integrity of consumed data streams via the DataSpace Node of a data consumer.

The trust layer's integrated distributed ledger technology is <a href="https://www.bigchaindb.com/" target="_blank">BigchainDB</a> with the Byzantine Fault-Tolerant consensus mechanism of the <a href="https://tendermint.com/" target="_blank">tendermint protocol</a>. The distributed ledger contains only signed hashes which doesn't leak any information. The hashes and signatures, generated by DataSpace Agents, allow the verification of the confidentiality, integrity and authenticity of the data streams.

>###Important Note:
>
>Our aim is to provide a trust layer solution that easy and seamless to integrate into existing infrastructures and ecosystems. According to the broad range of evolving technologies in the field of distributed ledgers and blockchains, we are continually evaluating emerging solutions in that field to provide the latest and proven technologies for our customers.
>
>In a further version of the DataSpace Kit, support for additional distributed ledger technologies is part of our development roadmap.

## Data Classification

The different kinds of data inside a DataSpace Ecosystem are classified into 3 types:

| Type          | Description |
| :---          |    :----    |
| Metadata      | Metadata of datasets is stored at the DataSpace Hub and will be cached at the client in order to provide metadata of datasets inside a DataSpace Ecosystem. |
| Data Streams   | Data streams remain without exception at the owner's DataSpace Node. Every DataSpace Node stores his own streams and all streams that has been shared with him.|
| Proofs        | Proofs, that are generated through the hashing and signing process of DataSpace Agents at the data’s source, are stored in the trust layer. The metadata (proof location) for each proof, that is required for verification and audit processes, is stored at the agent’s associated DataSpace Node and will be provided to other nodes if they consume that data stream portion. |

## Data Sharing Process

To provide a traceable and straightforward data sharing processes, we have implemented the publish-, request- and grant workflows for datasets into the admin web interface that is part of a DataSpace Node. Data sources and streams that are connected with DataSpace Nodes are structured into datasets that can be requested and shared with other DataSpace Nodes participating in the ecosystem.

The design of the data sharing process ensures that the control of data and sovereignty remains at each participating stakeholder and his DataSpace Node. The modular and fine-grained data access management enables a subscription in every possible combination of streams and time-frames for a dataset - to meet the demands of data providers and consumers.

| Workflow          | Description |
| :---          |    :----    |
| **Publish a Dataset**   | Dataset owners can publish a dataset (or just a part of it) to the whole ecosystem or only to selected DataSpace Nodes. A publication contains only descriptive metadata and not the data itself. A publication makes available datasets visible for other members inside a DataSpace Ecosystem. |
| **Request a Dataset**   | Every user of a DataSpace Node  within the ecosystem can create and send a request for selected streams, sources and time-frame to the owner of the dataset. |
| **Grant/Deny a Request**     |  Dataset owners can grant or deny submitted requests for their datasets. Once a request is confirmed, the synchronization starts and the data can be consumed by the requester via the integrated dashboards or via APIs. |
